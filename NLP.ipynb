{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad59de98",
   "metadata": {},
   "source": [
    "__NLP__ - Natural Language Processing обработка естественного языка - область знаний на стыке  информатики, лингвистики и искусственного интеллекта, направленная на изучение методов анализа и синтеза естественного языка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ebdc6",
   "metadata": {},
   "source": [
    "NLP — одно из направлений искуственного интеллекта, которое работает с анализом, пониманем и генерацией живых языков, для того, чтобы взаимодействовать с компьютерами и устно, и письменно, используя естественные языки вместо компьютерных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c5597",
   "metadata": {},
   "source": [
    "__Библиотека NLTK__ — пакет библиотек и программ для символьной и статистической обработки\n",
    "естественного языка, написанных на языке программирования Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de417f9",
   "metadata": {},
   "source": [
    "__Токены__ - текстовые единицы, на которые разбивается текст на естественном языке: символы, слова, словосочетания, предложения, абзацы и т.д. Чаще всего разбивают на слова."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7adec",
   "metadata": {},
   "source": [
    "Токены образуют __словарь__, который может быть отсортирован по алфавиту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0fbe7",
   "metadata": {},
   "source": [
    "__Документ__ - это совокупность токенов, которые принадлежат одной смыловой единице. В качестве документа может выступать предложение, комментарий или пост пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096dec51",
   "metadata": {},
   "source": [
    "__Корпус__ - это генеральная совокупность всех документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575e484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2cb9f7f",
   "metadata": {},
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668be98",
   "metadata": {},
   "source": [
    "1. Перевод всех букв в тексте в нижний регистр\n",
    "2. Удаление пунктуации и пробельных символов\n",
    "3. Токенизация по словам\n",
    "4. Удаление стоп слов\n",
    "5. Стемминг\n",
    "6. Лемматизация\n",
    "7. Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893dd592",
   "metadata": {},
   "source": [
    "__Токенизация__ (иногда – сегментация) по словам – это процесс разделения предложений на\n",
    "слова-компоненты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6ac25",
   "metadata": {},
   "source": [
    "__Cтемминг__ (от англ. stemming) — это поиск основы слова, учитывающий морфологию исходного слова.\n",
    "Стемминг выполняет морфологический разбор слова, находит общую для всех его грамматических\n",
    "форм основу, отсекая суффиксы и окончания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a4d19",
   "metadata": {},
   "source": [
    "__Лемматизация.__ Данный подход является альтернативой стемминга. Основная идея в приведении слова к словарной\n",
    "форме — лемме. \n",
    "Например для русского языка:\n",
    "\n",
    "для существительных — именительный падеж, единственное число;\n",
    "\n",
    "для прилагательных — именительный падеж, единственное число, мужской род;\n",
    "\n",
    "для глаголов, причастий, деепричастий — глагол в инфинитиве несовершенного вида.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c63631",
   "metadata": {},
   "source": [
    "Одна из основных библиотек для обработки естественного языка - pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8968b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69960d45",
   "metadata": {},
   "source": [
    "Векторное представление - сопоставление словам и фразам из некоторого словаря численных векторов, длина которых значительно меньше количества слов в словаре.\n",
    "\n",
    "__Векторизация__ - это процесс кодирования текста в виде целых чисел, то есть числовой формы для\n",
    "создания векторов признаков, чтобы алгоритмы машинного обучения могли понимать наши данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79806cde",
   "metadata": {},
   "source": [
    "### Векторизация. Прямое кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc6c4c",
   "metadata": {},
   "source": [
    "__Прямое кодирование (one-hot encoding)__ - самый простой способ преобразования токенов в тензоры (координатное представление вектора) и выполняется следующим способом:\n",
    "- каждый токен представляет бинарный вектор (значения 0 или 1)\n",
    "- единица ставится тому элементу, который соответствует номеру токена в словаре\n",
    "\n",
    "Проблемой прямого кодирования является размерность\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b6fc3",
   "metadata": {},
   "source": [
    "### Векторизация. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ce16e",
   "metadata": {},
   "source": [
    "Модель мешка слов (Bag of Words, BoW) - для документа формируется вектор размерности словаря и записывается признак насколько часто слово встречается в нем. Этот метод не учитывает важность того или иного токена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039b79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a38f4fab",
   "metadata": {},
   "source": [
    "### Векторизация. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec62548",
   "metadata": {},
   "source": [
    "TF-IDF (TF - Term Frequency - как часто слово встречается в документе (важность слова в контексте документа), IDF - Inverce Document Frequency) - статистическая мера, используемая для оценки важности слова в контексте документа, являющегося частью коллекции документов или корпуса. Вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции (важность слова возрастает, если он используется в одном документе и не используется в других)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08527c",
   "metadata": {},
   "source": [
    "TF считается для токенов документа, IDF - токенов всего корпуса. В TF-IDF редкие слова и слова, которые встречаются во всех документах, несут мало информации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab968701",
   "metadata": {},
   "source": [
    "### Вложение слов (Words Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae2f11",
   "metadata": {},
   "source": [
    "Вложение слов - это методика моделирования языка, используемая для отображения слов на векторы действительных чисел. Это тип представления слов, который позволяет словам с близким значением иметь сходное представление."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9988fd",
   "metadata": {},
   "source": [
    "Слова или фразы представляются в векторном пространстве с несколькими измерениями и могут генерироваться с использованием различных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2db5d2",
   "metadata": {},
   "source": [
    "###  Векторизация. Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222fcee9",
   "metadata": {},
   "source": [
    "Word2vec - технология от компании Google, которая заточена на статистическую обработку больших массивов текстовой информации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8d1af",
   "metadata": {},
   "source": [
    "Реализованы два основных алгоритма обучения:\n",
    "- CBoW (Continuonus Bag of Words, \"непрерывный мешок со словами\") архитектурное решение, которое предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "- Skip-gram, подход, действующий наоборот: использует текущее слово, чтобы предугадать окружающте его слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be98cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
